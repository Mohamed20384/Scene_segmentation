# Scene_segmentation
 
![image](https://github.com/user-attachments/assets/51a79e56-247c-4b17-8bbd-ca35dda8b9d2)

The most prevalent part of self-driving is semantic segmentation, which associates image pixels with useful labels such as sign, light, curb, road, vehicle etc. The main use for segmentation is to identify the drivable surface, which aids in ground plane estimation, object detection and lane boundary assessment. Segmentation labels are also being directly integrated into object detection as pixel masks, for static objects such as signs, lights and lanes, and moving objects such cars, trucks, bicycles and pedestrians.



![image](https://github.com/user-attachments/assets/83952013-a41e-41a7-a81c-1f62e3395cee)

Seamless Scene Segmentation is a CNN-based architecture that can be trained end-to-end to predict a complete class- and instance-specific labeling for each pixel in an image. To tackle this task, also known as "Panoptic Segmentation", we take advantage of a novel segmentation head that seamlessly integrates multi-scale features generated by a Feature Pyramid Network with contextual information conveyed by a light-weight DeepLab-like module.



![image](https://github.com/user-attachments/assets/194923e1-32ea-421f-9527-74b21499d7fc)

The State of the Art model for semantic segmentaiton (DeepLabV3+)
DeepLab is a leading series of image semantic segmentation models renowned for their exceptional performance in pixel-level classification tasks. The latest iteration, DeepLabv3+, represents the state-of-the-art in this domain. One of its key innovations is the integration of the atrous spatial pyramid pooling (ASPP) operation, strategically placed at the end of the encoder.



We trained MobileNetV2 on the Cityscapes dataset specifically to improve its performance in semantic segmentation tasks tailored for Egyptian streets. This fine-tuning process optimized the model's ability to accurately classify objects and delineate semantic regions within urban scenes commonly found in Egyptian cities. The trained MobileNetV2 model now exhibits enhanced capabilities for scene understanding, making it a valuable asset for applications such as urban planning and autonomous navigation in Egyptian urban environments.
Final output example

![Classes](https://github.com/user-attachments/assets/d69f832c-c945-480a-835b-c4356625153e)


OUTPUT 

![seg](https://github.com/user-attachments/assets/43f5e868-52ad-42ec-96a2-156119382e0c)

